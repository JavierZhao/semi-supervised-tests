{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2, Parts C-E: Neural Network\n",
    "\n",
    "In this Jupyter notebook, we will train a neural network on the MiniBooNE dataset.\n",
    "\n",
    "Use this notebook to write your code for problem 1 parts C-E by filling in the sections marked `# TODO` and running all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_openml(\"miniboone\", parser=\"auto\", version=1)\n",
    "X, y = data[\"data\"].values, (data[\"target\"].values == \"True\").astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 18:37:36.736070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 18:37:36.893101: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-03 18:37:37.818386: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-03 18:37:37.818485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-03 18:37:37.818494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-03 18:37:39.209900: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 18:37:39.849275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22828 MB memory:  -> device: 0, name: TITAN RTX, pci bus id: 0000:60:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers.experimental import SGD\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Implement the Keras model instance\n",
    "# as described in part C\n",
    "# ==============================================\n",
    "activation_fc = \"tanh\"\n",
    "inputs = Input(shape=X_train.shape[1:])\n",
    "d1 = Dense(64, activation=activation_fc)(inputs)\n",
    "d2 = Dense(64, activation=activation_fc)(d1)\n",
    "d3 = Dense(64, activation=activation_fc)(d2)\n",
    "\n",
    "outputs = Dense(1, activation=\"sigmoid\")(d3)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Compile the model with SGD and binary\n",
    "# crossentropy loss\n",
    "# ==============================================\n",
    "model.compile(optimizer=SGD(learning_rate=0.01), loss=\"BinaryCrossentropy\")\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Fit the training data for 50 epochs\n",
    "# with a batch size of 128\n",
    "# ==============================================\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=128, epochs=50)\n",
    "\n",
    "# retrieve predictions\n",
    "preds_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roc_helper import plot_roc\n",
    "\n",
    "plot_roc(y_test, preds_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# TODO: Implement the Keras model instance\n",
    "# as described in part D\n",
    "# ==============================================\n",
    "inputs = Input(shape=X_train.shape[1:])\n",
    "outputs = ...\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Compile the model with SGD and binary\n",
    "# crossentropy loss\n",
    "# ==============================================\n",
    "model.compile(...)\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Fit the training data for 50 epochs\n",
    "# with a batch size of 128\n",
    "# ==============================================\n",
    "history = model.fit(...)\n",
    "\n",
    "# retreieve predictions\n",
    "preds_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Implement the scaler as described in\n",
    "# part E\n",
    "# ==============================================\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Implement the Keras model instance\n",
    "# as described in part E\n",
    "# ==============================================\n",
    "inputs = Input(shape=X_train.shape[1:])\n",
    "outputs = ...\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# ==============================================\n",
    "# TODO: Compile the model with Adam and binary\n",
    "# crossentropy loss\n",
    "# ==============================================\n",
    "model.compile(...)\n",
    "history = model.fit(...)\n",
    "\n",
    "preds_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_test, preds_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0ea348b636367bcdf67fd2d6d24251712b38670f61fdee14f28eb58fe74f081"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

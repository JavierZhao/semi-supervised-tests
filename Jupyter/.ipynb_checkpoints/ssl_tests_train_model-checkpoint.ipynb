{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T18:43:37.250985Z",
     "start_time": "2022-08-23T18:43:37.012258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssl-jet-vol/semi-supervised-tests/Jupyter\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T18:46:24.077348Z",
     "start_time": "2022-08-23T18:46:22.250143Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1OAfKz8Ys-W6",
    "outputId": "81b6db96-9b92-4941-ff58-35f0be0d8260"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MaskLabel, TransformerConv\n",
    "from torch_geometric.utils import index_to_mask\n",
    "\n",
    "from src.data.jetnet_graph import JetNetGraph\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')  #go up one directory\n",
    "from src.data.jetnet_graph import JetNetGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T18:47:46.734644Z",
     "start_time": "2022-08-23T18:47:21.694593Z"
    },
    "id": "YjJkozIOs4DD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset\n",
      "[██████████████████████████████████████████████████] 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ssl-jet-vol/semi-supervised-tests/Jupyter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mJetNetGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUniMP\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, num_classes, hidden_channels, num_layers, heads, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m):\n",
      "File \u001b[0;32m/ssl-jet-vol/semi-supervised-tests/Jupyter/../src/data/jetnet_graph.py:13\u001b[0m, in \u001b[0;36mJetNetGraph.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, max_jets)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_jets \u001b[38;5;241m=\u001b[39m max_jets\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:50\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m              transform: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m              pre_transform: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m              pre_filter: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/dataset.py:87\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch_geometric/data/dataset.py:170\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m    169\u001b[0m makedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "File \u001b[0;32m/ssl-jet-vol/semi-supervised-tests/Jupyter/../src/data/jetnet_graph.py:33\u001b[0m, in \u001b[0;36mJetNetGraph.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data \u001b[38;5;241m=\u001b[39m JetNet(jet_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_num_particles_jet_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir)\n\u001b[1;32m     32\u001b[0m data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_jets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_jets:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "root = \"/ssl-jet-vol/semi-supervised-tests/Jupyter\"\n",
    "dataset = JetNetGraph(root, max_jets=1_000, n_files=1)  # just use one file, 1k jets for fast testing\n",
    "\n",
    "class UniMP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, hidden_channels, num_layers, heads, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.label_emb = MaskLabel(self.num_classes, self.in_channels)\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        for i in range(1, num_layers + 1):\n",
    "            if i < num_layers:\n",
    "                out_channels = self.hidden_channels // heads\n",
    "                concat = True\n",
    "            else:\n",
    "                out_channels = self.num_classes\n",
    "                concat = False\n",
    "            conv = TransformerConv(in_channels, out_channels, heads, concat=concat, beta=True, dropout=dropout)\n",
    "            self.convs.append(conv)\n",
    "            in_channels = self.hidden_channels\n",
    "\n",
    "            if i < num_layers:\n",
    "                self.norms.append(torch.nn.LayerNorm(self.hidden_channels))\n",
    "\n",
    "    def forward(self, x, y, edge_index, label_mask):\n",
    "        x = self.label_emb(x, y, label_mask)\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = norm(conv(x, edge_index)).relu()\n",
    "        return self.convs[-1](x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_TB_JD3tH39"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = dataset.data.to(device)\n",
    "\n",
    "model = UniMP(in_channels=dataset.num_features, num_classes=5, hidden_channels=64, num_layers=3, heads=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "tv_frac = 0.10\n",
    "tv_num = math.ceil(data.num_nodes * tv_frac)\n",
    "splits = np.cumsum([data.num_nodes - 2 * tv_num, tv_num, tv_num])\n",
    "\n",
    "train_index = torch.tensor(np.arange(start=0, stop=splits[0]), dtype=torch.long)\n",
    "val_index = torch.tensor(np.arange(start=splits[0], stop=splits[1]), dtype=torch.long)\n",
    "test_index = torch.tensor(np.arange(start=splits[1], stop=data.num_nodes), dtype=torch.long)\n",
    "\n",
    "train_mask = index_to_mask(train_index, size=data.num_nodes)\n",
    "val_mask = index_to_mask(val_index, size=data.num_nodes)\n",
    "test_mask = index_to_mask(test_index, size=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BQ2azrUtGQs"
   },
   "outputs": [],
   "source": [
    "def train(label_rate=0.75):  # How many labels to use for propagation\n",
    "    model.train()\n",
    "\n",
    "    propagation_mask = MaskLabel.ratio_mask(train_mask, ratio=label_rate)\n",
    "    supervision_mask = train_mask ^ propagation_mask\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.y, data.edge_index, propagation_mask)\n",
    "    loss = F.cross_entropy(out[supervision_mask], data.y[supervision_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    propagation_mask = train_mask\n",
    "    out = model(data.x, data.y, data.edge_index, propagation_mask)\n",
    "    pred = out[val_mask].argmax(dim=-1)\n",
    "    val_acc = int((pred == data.y[val_mask]).sum()) / pred.size(0)\n",
    "\n",
    "    propagation_mask = train_mask | val_mask\n",
    "    out = model(data.x, data.y, data.edge_index, propagation_mask)\n",
    "    pred = out[test_mask].argmax(dim=-1)\n",
    "    test_acc = int((pred == data.y[test_mask]).sum()) / pred.size(0)\n",
    "\n",
    "    return val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM4EsZnPtEO1"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_acc, test_acc = test()\n",
    "    print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ssl-tests train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
